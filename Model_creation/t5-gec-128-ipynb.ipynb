{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-02T14:37:06.152869Z","iopub.execute_input":"2023-03-02T14:37:06.153358Z","iopub.status.idle":"2023-03-02T14:37:06.171323Z","shell.execute_reply.started":"2023-03-02T14:37:06.153301Z","shell.execute_reply":"2023-03-02T14:37:06.169779Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/data-gec/whole_data.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-03-02T14:37:08.965236Z","iopub.execute_input":"2023-03-02T14:37:08.965746Z","iopub.status.idle":"2023-03-02T14:37:17.435039Z","shell.execute_reply.started":"2023-03-02T14:37:08.965701Z","shell.execute_reply":"2023-03-02T14:37:17.433863Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/data-gec/whole_data.csv', dtype=str)\ndf = df.dropna()","metadata":{"execution":{"iopub.status.busy":"2023-03-02T14:37:20.364447Z","iopub.execute_input":"2023-03-02T14:37:20.365936Z","iopub.status.idle":"2023-03-02T14:37:24.573014Z","shell.execute_reply.started":"2023-03-02T14:37:20.365890Z","shell.execute_reply":"2023-03-02T14:37:24.571902Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df = df.drop('correct_input', axis=1)\ndf = df.drop('correct_output', axis = 1)","metadata":{"execution":{"iopub.status.busy":"2023-03-02T14:37:24.971792Z","iopub.execute_input":"2023-03-02T14:37:24.972468Z","iopub.status.idle":"2023-03-02T14:37:25.072778Z","shell.execute_reply.started":"2023-03-02T14:37:24.972422Z","shell.execute_reply":"2023-03-02T14:37:25.071630Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-02T14:37:29.353965Z","iopub.execute_input":"2023-03-02T14:37:29.354977Z","iopub.status.idle":"2023-03-02T14:37:29.370997Z","shell.execute_reply.started":"2023-03-02T14:37:29.354934Z","shell.execute_reply":"2023-03-02T14:37:29.369703Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                             correct  \\\n0  And he took in my favorite subjects like soccer .   \n1  Actually , he was the one who let me know abou...   \n2       His Kanji ability is much better than mine .   \n3  We have known each other for only half a year ...   \n4  I heard a sentence last night when I was watch...   \n\n                                           incorrect  \n0   And he took in my favorite subject like soccer .  \n1  Actually , who let me know about Lang   was him .  \n2       His Kanji's ability is much better than me .  \n3  We have known each other for only half a year ...  \n4  I heard a sentence last night when I watched TV .  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>correct</th>\n      <th>incorrect</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>And he took in my favorite subjects like soccer .</td>\n      <td>And he took in my favorite subject like soccer .</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Actually , he was the one who let me know abou...</td>\n      <td>Actually , who let me know about Lang   was him .</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>His Kanji ability is much better than mine .</td>\n      <td>His Kanji's ability is much better than me .</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>We have known each other for only half a year ...</td>\n      <td>We have known each other for only half a year ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I heard a sentence last night when I was watch...</td>\n      <td>I heard a sentence last night when I watched TV .</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df = df.rename(columns={'correct': 'target', 'incorrect': 'input'})","metadata":{"execution":{"iopub.status.busy":"2023-03-02T14:37:32.292325Z","iopub.execute_input":"2023-03-02T14:37:32.293496Z","iopub.status.idle":"2023-03-02T14:37:32.312028Z","shell.execute_reply.started":"2023-03-02T14:37:32.293401Z","shell.execute_reply":"2023-03-02T14:37:32.310968Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-02T14:37:34.287878Z","iopub.execute_input":"2023-03-02T14:37:34.288491Z","iopub.status.idle":"2023-03-02T14:37:34.300150Z","shell.execute_reply.started":"2023-03-02T14:37:34.288440Z","shell.execute_reply":"2023-03-02T14:37:34.298969Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                              target  \\\n0  And he took in my favorite subjects like soccer .   \n1  Actually , he was the one who let me know abou...   \n2       His Kanji ability is much better than mine .   \n3  We have known each other for only half a year ...   \n4  I heard a sentence last night when I was watch...   \n\n                                               input  \n0   And he took in my favorite subject like soccer .  \n1  Actually , who let me know about Lang   was him .  \n2       His Kanji's ability is much better than me .  \n3  We have known each other for only half a year ...  \n4  I heard a sentence last night when I watched TV .  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>input</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>And he took in my favorite subjects like soccer .</td>\n      <td>And he took in my favorite subject like soccer .</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Actually , he was the one who let me know abou...</td>\n      <td>Actually , who let me know about Lang   was him .</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>His Kanji ability is much better than mine .</td>\n      <td>His Kanji's ability is much better than me .</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>We have known each other for only half a year ...</td>\n      <td>We have known each other for only half a year ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I heard a sentence last night when I was watch...</td>\n      <td>I heard a sentence last night when I watched TV .</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"!pip install -q transformers","metadata":{"execution":{"iopub.status.busy":"2023-03-02T14:37:38.486171Z","iopub.execute_input":"2023-03-02T14:37:38.486789Z","iopub.status.idle":"2023-03-02T14:37:50.146764Z","shell.execute_reply.started":"2023-03-02T14:37:38.486752Z","shell.execute_reply":"2023-03-02T14:37:50.145469Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import T5Tokenizer, T5ForConditionalGeneration, AutoTokenizer","metadata":{"execution":{"iopub.status.busy":"2023-03-02T14:37:50.149274Z","iopub.execute_input":"2023-03-02T14:37:50.149997Z","iopub.status.idle":"2023-03-02T14:37:53.723126Z","shell.execute_reply.started":"2023-03-02T14:37:50.149948Z","shell.execute_reply":"2023-03-02T14:37:53.721906Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"t5_model = T5ForConditionalGeneration.from_pretrained('anujraymajhi/t5-GEC-128len-6e')\ntokenizer = AutoTokenizer.from_pretrained('t5-base')","metadata":{"execution":{"iopub.status.busy":"2023-03-02T14:37:53.725772Z","iopub.execute_input":"2023-03-02T14:37:53.726088Z","iopub.status.idle":"2023-03-02T14:38:15.295372Z","shell.execute_reply.started":"2023-03-02T14:37:53.726053Z","shell.execute_reply":"2023-03-02T14:38:15.294200Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.50k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acbd49fbd51b40319ba606e8c3fff579"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff740d91698c4230a0adba0a97ba2a79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"489fc4ad921e4373a19b09f43658827f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4abcdb5dbb74449956ef500a9463e3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75023d8eaaed4df1b98578a86b3def25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04dc4ce9ae344b0dacf4c13a645df4f6"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/models/t5/tokenization_t5_fast.py:165: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\nFor now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n  FutureWarning,\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q datasets","metadata":{"execution":{"iopub.status.busy":"2023-03-02T14:38:15.297649Z","iopub.execute_input":"2023-03-02T14:38:15.298429Z","iopub.status.idle":"2023-03-02T14:38:25.057575Z","shell.execute_reply.started":"2023-03-02T14:38:15.298372Z","shell.execute_reply":"2023-03-02T14:38:25.056235Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import Dataset\n\ndf_test = pd.read_csv(\"/kaggle/input/jflegtest/eval_total_dataset.csv\", dtype=str)\ntrain_dataset = Dataset.from_pandas(df)\ntest_dataset = Dataset.from_pandas(df_test)","metadata":{"execution":{"iopub.status.busy":"2023-03-02T14:42:24.666126Z","iopub.execute_input":"2023-03-02T14:42:24.667363Z","iopub.status.idle":"2023-03-02T14:42:25.276192Z","shell.execute_reply.started":"2023-03-02T14:42:24.667311Z","shell.execute_reply":"2023-03-02T14:42:25.274915Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2023-03-02T14:42:28.140657Z","iopub.execute_input":"2023-03-02T14:42:28.141049Z","iopub.status.idle":"2023-03-02T14:42:28.146478Z","shell.execute_reply.started":"2023-03-02T14:42:28.141015Z","shell.execute_reply":"2023-03-02T14:42:28.144965Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class GrammarDataset(Dataset):\n    def __init__(self, dataset, tokenizer,print_text=False):         \n        self.dataset = dataset\n        self.pad_to_max_length = False\n        self.tokenizer = tokenizer\n        self.print_text = print_text\n        self.max_len = 128\n  \n    def __len__(self):\n        return len(self.dataset)\n\n\n    def tokenize_data(self, example):\n        input_, target_ = example['input'], example['target']\n\n        # tokenize inputs\n        tokenized_inputs = tokenizer(input_, pad_to_max_length=self.pad_to_max_length, \n                                            max_length=self.max_len,\n                                            return_attention_mask=True, truncation = True)\n    \n        tokenized_targets = tokenizer(target_, pad_to_max_length=self.pad_to_max_length, \n                                            max_length=self.max_len,\n                                            return_attention_mask=True, truncation= True)\n\n        inputs={\"input_ids\": tokenized_inputs['input_ids'],\n            \"attention_mask\": tokenized_inputs['attention_mask'],\n            \"labels\": tokenized_targets['input_ids']\n        }\n        \n        return inputs\n\n  \n    def __getitem__(self, index):\n        inputs = self.tokenize_data(self.dataset[index])\n        \n        if self.print_text:\n            for k in inputs.keys():\n                print(k, len(inputs[k]))\n\n        return inputs","metadata":{"execution":{"iopub.status.busy":"2023-03-02T14:42:31.558021Z","iopub.execute_input":"2023-03-02T14:42:31.558503Z","iopub.status.idle":"2023-03-02T14:42:31.577720Z","shell.execute_reply.started":"2023-03-02T14:42:31.558459Z","shell.execute_reply":"2023-03-02T14:42:31.575114Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from datasets import load_metric\nrouge_metric = load_metric(\"rouge\")","metadata":{"execution":{"iopub.status.busy":"2023-02-27T13:56:03.711788Z","iopub.execute_input":"2023-02-27T13:56:03.712248Z","iopub.status.idle":"2023-02-27T13:56:05.625813Z","shell.execute_reply.started":"2023-02-27T13:56:03.712181Z","shell.execute_reply":"2023-02-27T13:56:05.62464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset","metadata":{"execution":{"iopub.status.busy":"2023-03-02T14:42:38.327534Z","iopub.execute_input":"2023-03-02T14:42:38.328012Z","iopub.status.idle":"2023-03-02T14:42:38.337314Z","shell.execute_reply.started":"2023-03-02T14:42:38.327964Z","shell.execute_reply":"2023-03-02T14:42:38.336106Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['target', 'input', '__index_level_0__'],\n    num_rows: 496295\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import (\n    T5ForConditionalGeneration, T5Tokenizer, \n    Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n  )","metadata":{"execution":{"iopub.status.busy":"2023-03-02T14:42:41.132836Z","iopub.execute_input":"2023-03-02T14:42:41.133205Z","iopub.status.idle":"2023-03-02T14:42:41.548797Z","shell.execute_reply.started":"2023-03-02T14:42:41.133172Z","shell.execute_reply":"2023-03-02T14:42:41.547719Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer, model=t5_model, padding='longest', return_tensors='pt')","metadata":{"execution":{"iopub.status.busy":"2023-03-02T14:42:43.714702Z","iopub.execute_input":"2023-03-02T14:42:43.715306Z","iopub.status.idle":"2023-03-02T14:42:43.720427Z","shell.execute_reply.started":"2023-03-02T14:42:43.715269Z","shell.execute_reply":"2023-03-02T14:42:43.719090Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nargs = Seq2SeqTrainingArguments(output_dir=\"kaggle/working/weights\",\n                        evaluation_strategy=\"steps\",\n                        per_device_train_batch_size=batch_size,\n                        per_device_eval_batch_size=batch_size,\n                        learning_rate=2e-5,\n                        num_train_epochs=3,\n                        weight_decay=0.01,\n                        save_total_limit=2,\n                        predict_with_generate=True,\n                        fp16 = True,\n                        gradient_accumulation_steps = 6,\n                        eval_steps = 625,\n                        save_steps = 2500,\n                        load_best_model_at_end=True,\n                        logging_dir=\"/logs\")","metadata":{"execution":{"iopub.status.busy":"2023-03-02T14:43:21.296344Z","iopub.execute_input":"2023-03-02T14:43:21.297358Z","iopub.status.idle":"2023-03-02T14:43:21.434239Z","shell.execute_reply.started":"2023-03-02T14:43:21.297318Z","shell.execute_reply":"2023-03-02T14:43:21.433140Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(model=t5_model, \n                args=args, \n                train_dataset= GrammarDataset(train_dataset, tokenizer),\n                eval_dataset=GrammarDataset(test_dataset, tokenizer),\n                tokenizer=tokenizer,\n                data_collator=data_collator)","metadata":{"execution":{"iopub.status.busy":"2023-03-02T14:43:24.382788Z","iopub.execute_input":"2023-03-02T14:43:24.383178Z","iopub.status.idle":"2023-03-02T14:43:29.608439Z","shell.execute_reply.started":"2023-03-02T14:43:24.383144Z","shell.execute_reply":"2023-03-02T14:43:29.607353Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"Using cuda_amp half precision backend\n","output_type":"stream"}]},{"cell_type":"code","source":"os.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2023-03-02T14:43:32.178070Z","iopub.execute_input":"2023-03-02T14:43:32.178837Z","iopub.status.idle":"2023-03-02T14:43:32.184001Z","shell.execute_reply.started":"2023-03-02T14:43:32.178796Z","shell.execute_reply":"2023-03-02T14:43:32.182822Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.training_step()","metadata":{"execution":{"iopub.status.busy":"2023-03-02T18:35:20.457525Z","iopub.execute_input":"2023-03-02T18:35:20.458400Z","iopub.status.idle":"2023-03-02T18:35:20.513282Z","shell.execute_reply.started":"2023-03-02T18:35:20.458353Z","shell.execute_reply":"2023-03-02T18:35:20.511226Z"},"trusted":true},"execution_count":29,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_24/1692554117.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: training_step() missing 2 required positional arguments: 'model' and 'inputs'"],"ename":"TypeError","evalue":"training_step() missing 2 required positional arguments: 'model' and 'inputs'","output_type":"error"}]},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2023-03-02T18:17:31.830500Z","iopub.execute_input":"2023-03-02T18:17:31.831544Z","iopub.status.idle":"2023-03-02T18:17:35.252723Z","shell.execute_reply.started":"2023-03-02T18:17:31.831503Z","shell.execute_reply":"2023-03-02T18:17:35.251123Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 800\n  Batch size = 64\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [13/13 00:03]\n    </div>\n    "},"metadata":{}},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.3520869314670563,\n 'eval_runtime': 3.4078,\n 'eval_samples_per_second': 234.753,\n 'eval_steps_per_second': 3.815,\n 'epoch': 3.0}"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model('t5-GEC-128len-9e')","metadata":{"execution":{"iopub.status.busy":"2023-03-02T18:17:46.676945Z","iopub.execute_input":"2023-03-02T18:17:46.678239Z","iopub.status.idle":"2023-03-02T18:17:48.071557Z","shell.execute_reply.started":"2023-03-02T18:17:46.678184Z","shell.execute_reply":"2023-03-02T18:17:48.070283Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"Saving model checkpoint to t5-GEC-128len-9e\nConfiguration saved in t5-GEC-128len-9e/config.json\nConfiguration saved in t5-GEC-128len-9e/generation_config.json\nModel weights saved in t5-GEC-128len-9e/pytorch_model.bin\ntokenizer config file saved in t5-GEC-128len-9e/tokenizer_config.json\nSpecial tokens file saved in t5-GEC-128len-9e/special_tokens_map.json\nCopy vocab file to t5-GEC-128len-9e/spiece.model\n","output_type":"stream"}]},{"cell_type":"code","source":"!tar -zcvf t5-GEC-128len-9e.tar.gz /kaggle/working/t5-GEC-128len-9e","metadata":{"execution":{"iopub.status.busy":"2023-03-02T18:18:08.980950Z","iopub.execute_input":"2023-03-02T18:18:08.981513Z","iopub.status.idle":"2023-03-02T18:18:56.887111Z","shell.execute_reply.started":"2023-03-02T18:18:08.981473Z","shell.execute_reply":"2023-03-02T18:18:56.885387Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\ntar: Removing leading `/' from member names\n/kaggle/working/t5-GEC-128len-9e/\n/kaggle/working/t5-GEC-128len-9e/training_args.bin\n/kaggle/working/t5-GEC-128len-9e/spiece.model\n/kaggle/working/t5-GEC-128len-9e/special_tokens_map.json\n/kaggle/working/t5-GEC-128len-9e/generation_config.json\n/kaggle/working/t5-GEC-128len-9e/config.json\n/kaggle/working/t5-GEC-128len-9e/tokenizer_config.json\n/kaggle/working/t5-GEC-128len-9e/tokenizer.json\n/kaggle/working/t5-GEC-128len-9e/pytorch_model.bin\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd /kaggle/working\nfrom IPython.display import FileLink\nFileLink('t5-GEC-128len-9e.tar.gz')","metadata":{"execution":{"iopub.status.busy":"2023-03-02T18:19:55.628749Z","iopub.execute_input":"2023-03-02T18:19:55.629635Z","iopub.status.idle":"2023-03-02T18:19:55.650337Z","shell.execute_reply.started":"2023-03-02T18:19:55.629566Z","shell.execute_reply":"2023-03-02T18:19:55.649212Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/t5-GEC-128len-9e.tar.gz","text/html":"<a href='t5-GEC-128len-9e.tar.gz' target='_blank'>t5-GEC-128len-9e.tar.gz</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}